{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3da1b154",
   "metadata": {},
   "source": [
    "# Procesamiento de Texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3eaf62d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unidecode in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.4.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: spacy in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (3.8.7)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from spacy) (1.0.13)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from spacy) (3.0.10)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from spacy) (8.3.6)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from spacy) (0.16.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from spacy) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from spacy) (2.3.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from spacy) (2.32.4)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from spacy) (2.11.7)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from spacy) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from spacy) (80.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\acca4\\appdata\\roaming\\python\\python313\\site-packages (from spacy) (25.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.14.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.8.3)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\acca4\\appdata\\roaming\\python\\python313\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (14.1.0)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.3.0.post1)\n",
      "Requirement already satisfied: wrapt in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\acca4\\appdata\\roaming\\python\\python313\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jinja2->spacy) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting es-core-news-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.8.0/es_core_news_sm-3.8.0-py3-none-any.whl (12.9 MB)\n",
      "     ---------------------------------------- 0.0/12.9 MB ? eta -:--:--\n",
      "     --------------------- ------------------ 6.8/12.9 MB 35.8 MB/s eta 0:00:01\n",
      "     --------------------------------------  12.6/12.9 MB 30.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.9/12.9 MB 28.2 MB/s  0:00:00\n",
      "Installing collected packages: es-core-news-sm\n",
      "Successfully installed es-core-news-sm-3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('es_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "%pip install unidecode\n",
    "%pip install spacy\n",
    "!python -m spacy download es_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfea65d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: click in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nltk) (8.2.1)\n",
      "Collecting joblib (from nltk)\n",
      "  Downloading joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Downloading regex-2025.7.34-cp313-cp313-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\acca4\\appdata\\roaming\\python\\python313\\site-packages (from click->nltk) (0.4.6)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.5/1.5 MB 23.9 MB/s  0:00:00\n",
      "Downloading regex-2025.7.34-cp313-cp313-win_amd64.whl (275 kB)\n",
      "Downloading joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Installing collected packages: regex, joblib, nltk\n",
      "\n",
      "   ---------------------------------------- 0/3 [regex]\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   ---------------------------------------- 3/3 [nltk]\n",
      "\n",
      "Successfully installed joblib-1.5.1 nltk-3.9.1 regex-2025.7.34\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script nltk.exe is installed in 'c:\\Users\\acca4\\AppData\\Local\\Programs\\Python\\Python313\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "%pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c7c82b",
   "metadata": {},
   "source": [
    "## Pasos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa64add",
   "metadata": {},
   "source": [
    "### 1. Limpieza\n",
    "\n",
    "El objetivo de este paso es hacer un reemplazo de simbologia del español, puntuación, etc.\n",
    "Se podría hacer uso de .replace() de python. Sin embargo se trabaja con expresiones regulares, en este caso la libreria \"re\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "486d6bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Hola  mundo   Cómo estás      '"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def limpiar(texto):\n",
    "    puntuación = r'[,;.:¡!¿?@#$%&[\\](){}<>~=+\\-*/|\\\\_^`\"\\']'\n",
    "    \n",
    "    # signos de puntuación\n",
    "    texto = re.sub(puntuación, ' ', texto)\n",
    "    \n",
    "    # dígitos [0-9]\n",
    "    # Se usa \\d para representar dígitos usualmente.\n",
    "    texto = re.sub('[0-9]', ' ', texto)\n",
    "\n",
    "    return texto\n",
    "\n",
    "ejemplo = \"¡Hola, mundo! ¿Cómo estás? 1234\"\n",
    "resultado = limpiar(ejemplo)\n",
    "resultado\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbfa940",
   "metadata": {},
   "source": [
    "### 2. Paso\n",
    "\n",
    "Ejemplo:\n",
    "- 13/03/30 -> trece de marzo de dos mil treinta\n",
    "- DC -> departamento de computación\n",
    "\n",
    "Es necesario ahora normalizar, osea, para el español eliminar tildes, convertir todo a minusculas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260e2336",
   "metadata": {},
   "source": [
    "Si bien podemos hacerlo de manera manual, se puede usar \"unicode\" para lograrlo en caso que se tenga caracteres chinos o letras extranjeras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bd67a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' hola  mundo   como estas      '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalizar(texto):\n",
    "\n",
    "    # todo a minúsculas\n",
    "    texto = texto.lower()\n",
    "\n",
    "    # tildes y diacríticas\n",
    "    texto = re.sub('á', 'a', texto)\n",
    "    texto = re.sub('é', 'e', texto)\n",
    "    texto = re.sub('í', 'i', texto)\n",
    "    texto = re.sub('ó', 'o', texto)\n",
    "    texto = re.sub('ú', 'u', texto)\n",
    "    texto = re.sub('ü', 'u', texto)\n",
    "    texto = re.sub('ñ', 'n', texto)\n",
    "\n",
    "    return texto\n",
    "\n",
    "resultado_normalizado = normalizar(resultado)\n",
    "resultado_normalizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9530e5d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Hola  mundo   Como estas      '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Opcion 2 Unicode\n",
    "\n",
    "from unidecode import unidecode\n",
    "\n",
    "resultado_normalizado2 = unidecode(resultado)\n",
    "resultado_normalizado2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df496d1",
   "metadata": {},
   "source": [
    "### Paso 3: Finalmente, tokenización\n",
    "Separar el texto en partes mas pequeñas. Hay muchas modalidades y hay que tener mucho cuidado, sobretodo en situación donde la puntuación puede ser seperador. En ingles tenemos \"it's\" , que podría separarse como it - 's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acc93664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hola', 'mundo', 'Como', 'estas']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenizar(texto):\n",
    "    # IMPORTANTE: podría devolver una lista vacía\n",
    "    return [tóken for tóken in texto.split()]\n",
    "    \n",
    "ejemplo_tokenizado = tokenizar(resultado_normalizado2)\n",
    "ejemplo_tokenizado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db68326d",
   "metadata": {},
   "source": [
    "Entonces, ahora usando spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3525815c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Esto', 'es', 'una', 'frase', '.']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('es_core_news_sm')\n",
    "\n",
    "doc = nlp('Esto es una frase.')\n",
    "\n",
    "print([tóken.text for tóken in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2a97f6",
   "metadata": {},
   "source": [
    "### Stemming\n",
    "\n",
    "Stem, de raíz, reduce la inflección de las palabras, mapeando un grupo de palabras a la misma raíz, sin importar si la raíz es una palabras válida en el lenguaje."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66992de9",
   "metadata": {},
   "source": [
    "### Lemmatization\n",
    "\n",
    "A diferencia del stemming, la lematización reduce las palabras inflexadas a palabras que pertenecen al lenguaje. La raíz pasa a llamarse lema."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da98dde1",
   "metadata": {},
   "source": [
    "# Trabajando con NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18118487",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\acca4\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['de', 'la', 'que', 'el', 'en', 'y', 'a', 'los', 'del', 'se']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopwords.words('spanish')[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262bab39",
   "metadata": {},
   "source": [
    "#  Ejemplo en Python con spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83c4fd19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['¡', 'Hola', '!', 'Estoy', 'aprendiendo', 'procesamiento', 'de', 'lenguaje', 'natural', 'con', 'Python', '.']\n",
      "Lemmas: ['¡', 'Hola', '!', 'estar', 'aprender', 'procesamiento', 'de', 'lenguaje', 'natural', 'con', 'Python', '.']\n",
      "Tokens filtrados: ['Hola', 'aprendiendo', 'procesamiento', 'lenguaje', 'natural', 'Python']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# 1. Cargar modelo en español\n",
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "\n",
    "# 2. Texto de ejemplo\n",
    "texto = \"¡Hola! Estoy aprendiendo procesamiento de lenguaje natural con Python.\"\n",
    "\n",
    "# 3. Procesar texto\n",
    "doc = nlp(texto)\n",
    "\n",
    "# 4. Tokenización\n",
    "tokens = [token.text for token in doc]\n",
    "print(\"Tokens:\", tokens)\n",
    "\n",
    "# 5. Lemmatización\n",
    "lemmas = [token.lemma_ for token in doc]\n",
    "print(\"Lemmas:\", lemmas)\n",
    "\n",
    "# 6. Filtrar solo palabras significativas (sin puntuación ni stopwords)\n",
    "tokens_filtrados = [token.text for token in doc if not token.is_stop and token.is_alpha]\n",
    "print(\"Tokens filtrados:\", tokens_filtrados)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a288c5",
   "metadata": {},
   "source": [
    "# Ejemplo rápido con HuggingFace Tokenizers (sub-palabras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e0f2347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.55.0-py3-none-any.whl.metadata (39 kB)\n",
      "Collecting filelock (from transformers)\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.34.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (2.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\acca4\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (25.0)\n",
      "Collecting pyyaml>=5.1 (from transformers)\n",
      "  Downloading PyYAML-6.0.2-cp313-cp313-win_amd64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (2025.7.34)\n",
      "Requirement already satisfied: requests in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (2.32.4)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.4-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.6.2-cp38-abi3-win_amd64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.34.0->transformers)\n",
      "  Downloading fsspec-2025.7.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\acca4\\appdata\\roaming\\python\\python313\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers) (2025.8.3)\n",
      "Downloading transformers-4.55.0-py3-none-any.whl (11.3 MB)\n",
      "   ---------------------------------------- 0.0/11.3 MB ? eta -:--:--\n",
      "   ------------------- -------------------- 5.5/11.3 MB 28.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.0/11.3 MB 28.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.3/11.3 MB 26.5 MB/s  0:00:00\n",
      "Downloading huggingface_hub-0.34.4-py3-none-any.whl (561 kB)\n",
      "   ---------------------------------------- 0.0/561.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 561.5/561.5 kB 20.8 MB/s  0:00:00\n",
      "Downloading tokenizers-0.21.4-cp39-abi3-win_amd64.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.5/2.5 MB 25.3 MB/s  0:00:00\n",
      "Downloading fsspec-2025.7.0-py3-none-any.whl (199 kB)\n",
      "Downloading PyYAML-6.0.2-cp313-cp313-win_amd64.whl (156 kB)\n",
      "Downloading safetensors-0.6.2-cp38-abi3-win_amd64.whl (320 kB)\n",
      "Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: safetensors, pyyaml, fsspec, filelock, huggingface-hub, tokenizers, transformers\n",
      "\n",
      "   ----- ---------------------------------- 1/7 [pyyaml]\n",
      "   ----- ---------------------------------- 1/7 [pyyaml]\n",
      "   ----------- ---------------------------- 2/7 [fsspec]\n",
      "   ----------- ---------------------------- 2/7 [fsspec]\n",
      "   ----------- ---------------------------- 2/7 [fsspec]\n",
      "   ----------- ---------------------------- 2/7 [fsspec]\n",
      "   ----------- ---------------------------- 2/7 [fsspec]\n",
      "   ----------- ---------------------------- 2/7 [fsspec]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [huggingface-hub]\n",
      "   ---------------------------- ----------- 5/7 [tokenizers]\n",
      "   ---------------------------- ----------- 5/7 [tokenizers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [transformers]\n",
      "   ---------------------------------------- 7/7 [transformers]\n",
      "\n",
      "Successfully installed filelock-3.18.0 fsspec-2025.7.0 huggingface-hub-0.34.4 pyyaml-6.0.2 safetensors-0.6.2 tokenizers-0.21.4 transformers-4.55.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts hf.exe, huggingface-cli.exe and tiny-agents.exe are installed in 'c:\\Users\\acca4\\AppData\\Local\\Programs\\Python\\Python313\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts transformers-cli.exe and transformers.exe are installed in 'c:\\Users\\acca4\\AppData\\Local\\Programs\\Python\\Python313\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e9511ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\acca4\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "c:\\Users\\acca4\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\acca4\\.cache\\huggingface\\hub\\models--bert-base-multilingual-cased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['¡', 'Ho', '##la', '!', 'Esto', '##y', 'apre', '##ndi', '##endo', 'procesa', '##miento', 'de', 'lenguaje', 'natural', 'con', 'Python', '.']\n",
      "IDs: [199, 20220, 10330, 106, 24165, 10157, 87438, 17938, 17560, 103862, 16085, 10104, 65621, 13409, 10173, 47294, 119]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Tokenizador preentrenado (multilingüe)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "\n",
    "texto = \"¡Hola! Estoy aprendiendo procesamiento de lenguaje natural con Python.\"\n",
    "\n",
    "# Tokenización por sub-palabras\n",
    "tokens = tokenizer.tokenize(texto)\n",
    "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "print(\"Tokens:\", tokens)\n",
    "print(\"IDs:\", ids)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
