{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89ecd3d9",
   "metadata": {},
   "source": [
    "# Preambulo:\n",
    "\n",
    "* **Fecha de entrega**: Miercoles 27 de Agosto 6pm. \n",
    "* **Reglas de codificación**: Use jupyter notebooks (python) incluyendo resultados ejecutados. Todas las clases, métodos, funciones y código libre DEBEN contener docstrings con una explicación detallada. Especifique lineas a cambiar.\n",
    "* **Informe**: Incluir informe escrito en **_pdf_** con las respuestas a las preguntas y un breve resumen de la implementación.\n",
    "* **Envío**: Grupos de maximo tres. Envío en Zip. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa0d12d",
   "metadata": {},
   "source": [
    "# Metricas de evualiación de IR (Python + Numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450358b6",
   "metadata": {},
   "source": [
    "## Importaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18b902ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99910268",
   "metadata": {},
   "source": [
    "## Metricas\n",
    "\n",
    "### Precisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb55d21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def precision(query: list) -> float:\n",
    "    \"\"\"\n",
    "    Calcula la precisión para una consulta de recuperación de información.\n",
    "\n",
    "    La precisión se define como la proporción de elementos relevantes recuperados\n",
    "    (representados por 1 en la lista) respecto al total de elementos recuperados.\n",
    "\n",
    "    Args:\n",
    "        query (list): Lista de enteros (0 o 1) donde 1 indica un elemento relevante.\n",
    "\n",
    "    Returns:\n",
    "        float: Precisión de la consulta. Si la lista está vacía, retorna 0.0.\n",
    "    \"\"\"\n",
    "    return np.mean(query) if query else 0.0\n",
    "\n",
    "# Ejemplo dado\n",
    "query = [0,0,0,1]\n",
    "\n",
    "precision(query).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490fa2bb",
   "metadata": {},
   "source": [
    "### K-Precisión (P@K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b1ee154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def precision_at_k(query: list, k: int) -> float:\n",
    "    \"\"\"\n",
    "    Calcula la precisión en los primeros k elementos de una consulta de recuperación de información.\n",
    "\n",
    "    Args:\n",
    "        query (list): Lista de enteros (0 o 1) donde 1 indica un elemento relevante.\n",
    "        k (int): Número de elementos a considerar desde el inicio de la lista.\n",
    "\n",
    "    Returns:\n",
    "        float: Precisión en los primeros k elementos. Si k es mayor que el tamaño de la lista, \n",
    "        se considera toda la lista. Si la lista está vacía, retorna 0.0.\n",
    "    \"\"\"\n",
    "    k = min(k, len(query))\n",
    "    return precision(query[:k])\n",
    "\n",
    "\n",
    "# Ejemplo dado\n",
    "query = [0,0,0,1]\n",
    "k = 1\n",
    "precision_at_k(query, k).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eaf86cc",
   "metadata": {},
   "source": [
    "### K-recall (R@K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d18ba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def recall_at_k(query: list, k: int, docs_relevantes: int) -> float:\n",
    "    \"\"\"\n",
    "    Calcula el recall en los primeros k elementos de una consulta de recuperación de información.\n",
    "\n",
    "    Args:\n",
    "        query (list): Lista de enteros (0 o 1) donde 1 indica un elemento relevante.\n",
    "        k (int): Número de elementos a considerar desde el inicio de la lista.\n",
    "        docs_relevantes (int): Número total de documentos relevantes en la colección.\n",
    "\n",
    "    Returns:\n",
    "        float: Recall en los primeros k elementos. Si docs_relevantes es 0, retorna 0.0.\n",
    "    \"\"\"\n",
    "    k = min(k, len(query))\n",
    "    return np.sum(query[:k]) / docs_relevantes if docs_relevantes else 0.0\n",
    "\n",
    "# Ejemplo dado\n",
    "query = [0,0,0,1]\n",
    "k = 1\n",
    "docs_relevantes = 4\n",
    "recall_at_k(query, k, docs_relevantes).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8328de9e",
   "metadata": {},
   "source": [
    "### Average Precision (A-P@K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5ffab74e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def average_precision(query: list) -> float:\n",
    "    \"\"\"\n",
    "    Calcula la precisión promedio de una consulta de recuperación de información.\n",
    "\n",
    "    La precisión promedio se define como la media de las precisiones en cada posición\n",
    "    donde se recupera un elemento relevante.\n",
    "\n",
    "    Args:\n",
    "        query (list): Lista de enteros (0 o 1) donde 1 indica un elemento relevante.\n",
    "\n",
    "    Returns:\n",
    "        float: Precisión promedio de la consulta. Si no hay elementos relevantes, retorna 0.0.\n",
    "    \"\"\"\n",
    "    precisions = [precision_at_k(query, i) for i in range(1, len(query) + 1) if query[i - 1] == 1]\n",
    "            \n",
    "    return np.mean(precisions) if precisions else 0.0\n",
    "\n",
    "# Ejemplo dado\n",
    "query = [0,1,0,1,1,1,1]\n",
    "\n",
    "np.round(average_precision(query), 2).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cd01d1",
   "metadata": {},
   "source": [
    "### Mean Average Precisión (MAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e3999e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAP(queries: list) -> float:\n",
    "    \"\"\"\n",
    "    Calcula la Precisión Promedio Media (MAP) para un conjunto de consultas.\n",
    "\n",
    "    La MAP es la media de las precisiones promedio de cada consulta.\n",
    "\n",
    "    Args:\n",
    "        queries (list): Lista de listas, donde cada sublista representa una consulta.\n",
    "\n",
    "    Returns:\n",
    "        float: MAP del conjunto de consultas. Si no hay consultas, retorna 0.0.\n",
    "    \"\"\"\n",
    "    \n",
    "    return np.mean([average_precision(query) for query in queries]) if queries else 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4acefa1",
   "metadata": {},
   "source": [
    "### K-DCG (DCG@K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4c01568f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.2796"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def DCG_at_K(query: list, k: int) -> float:\n",
    "    \"\"\"\n",
    "    Calcula el Discounted Cumulative Gain (DCG) en los primeros k elementos de una consulta.\n",
    "\n",
    "    Args:\n",
    "        query (list): Lista de enteros (0 o 1) donde 1 indica un elemento relevante.\n",
    "        k (int): Número de elementos a considerar desde el inicio de la lista.\n",
    "\n",
    "    Returns:\n",
    "        float: DCG en los primeros k elementos. Si la lista está vacía, retorna 0.0.\n",
    "    \"\"\"\n",
    "    k = min(k, len(query))\n",
    "    return np.sum([query[i-1] / np.log2(max(i, 2)) for i in range(1, k+1)]) if k > 0 else 0.0\n",
    "\n",
    "# Ejemplo dado\n",
    "query =  [4, 4, 3, 0, 0, 1, 3, 3, 3, 0]\n",
    "k = 6\n",
    "np.round(DCG_at_K(query, k), 4).item()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34de71a",
   "metadata": {},
   "source": [
    "### K-NDCG (NDCG@K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e9945057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7425"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def NDCG_at_k(query: list, k: int) -> float:\n",
    "    \"\"\"\n",
    "    Calcula el Normalized Discounted Cumulative Gain (NDCG) para una consulta.\n",
    "\n",
    "    Args:\n",
    "        query (list): Lista de enteros (0 o 1) donde 1 indica un elemento relevante.\n",
    "\n",
    "    Returns:\n",
    "        float: NDCG de la consulta. Si la lista está vacía, retorna 0.0.\n",
    "    \"\"\"\n",
    "    dcg = DCG_at_K(query, k)\n",
    "    idcg = DCG_at_K(sorted(query, reverse=True), k)\n",
    "    return dcg / idcg if idcg > 0 else 0.0\n",
    "\n",
    "# Ejemplo dado\n",
    "query =  [4, 4, 3, 0, 0, 1, 3, 3, 3, 0]\n",
    "k = 6\n",
    "\n",
    "np.round(NDCG_at_k(query, k), 4).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf30326",
   "metadata": {},
   "source": [
    "# Preprocesamiento de XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d10ec9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (6.0.0)\n",
      "Requirement already satisfied: spacy in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (3.8.7)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from spacy) (1.0.13)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from spacy) (3.0.10)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from spacy) (8.3.6)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from spacy) (0.16.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from spacy) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from spacy) (2.3.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from spacy) (2.32.4)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from spacy) (2.11.7)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from spacy) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from spacy) (80.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\acca4\\appdata\\roaming\\python\\python313\\site-packages (from spacy) (25.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.14.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.8.3)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\acca4\\appdata\\roaming\\python\\python313\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (14.1.0)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.3.0.post1)\n",
      "Requirement already satisfied: wrapt in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\acca4\\appdata\\roaming\\python\\python313\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jinja2->spacy) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     -------- ------------------------------- 2.6/12.8 MB 13.6 MB/s eta 0:00:01\n",
      "     ---------------- ----------------------- 5.2/12.8 MB 12.8 MB/s eta 0:00:01\n",
      "     ---------------------- ----------------- 7.1/12.8 MB 12.2 MB/s eta 0:00:01\n",
      "     -------------------------- ------------- 8.4/12.8 MB 10.4 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 10.5/12.8 MB 9.8 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.3/12.8 MB 9.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.8/12.8 MB 9.0 MB/s  0:00:01\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "Requirement already satisfied: lxml in c:\\users\\acca4\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (6.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install lxml spacy\n",
    "!python -m spacy download en_core_web_sm\n",
    "%pip install lxml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23615345",
   "metadata": {},
   "source": [
    "## Importaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0f59ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "import spacy\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdda6a09",
   "metadata": {},
   "source": [
    "## Extracción, tokenización y almacenamiento\n",
    "### Extracción y tokenización (Única)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e57ef4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['william',\n",
       " 'beaumont',\n",
       " 'human',\n",
       " 'digestion',\n",
       " 'william',\n",
       " 'beaumont',\n",
       " 'physiology',\n",
       " 'digestion',\n",
       " 'image',\n",
       " 'source']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xml_data = \"\"\"<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
    "<NAF xml:lang=\"en\" version=\"v3\">\n",
    "  <nafHeader>\n",
    "    <fileDesc title=\"Juan Bautista de Anza and the Route to San Francisco Bay\" />\n",
    "    <public publicId=\"d331\" uri=\"http://blog.yovisto.com/juan-bautista-de-anza-and-the-route-to-san-francisco-bay/\" />\n",
    "  </nafHeader>\n",
    "  <raw><![CDATA[Juan Bautista de Anza and the Route to San Francisco Bay.\n",
    "\n",
    "Juan Bautista de Anza, from a portrait in oil by Fray Orsi in 1774.  On March 28, 1776, Basque New-Spanish explorer Juan Bautista de Anza was the first to reach the San Francisco Bay by land. De Anza was the first European to establish an overland route from Mexico, through the Sonoran Desert, to the Pacific coast of California. New World Spanish explorers had been seeking such a route through the desert southwest for more than two centuries. Juan Bautista de Anza was born in Sonora, New Spain in 1736. De Anza enlisted in the army at the Presidio of Fronteras in 1752 and became a captain in 1760. De Anza proposed an expedition to Alta California in the early 1770s. The region had been colonized in the late 1760s and the colonies had been established at San Diego and Monterey. Still, a direct land route was desired and De Anza’s mission was apporoved by the King of Spain and on January 8, 1774. The expedition including 20 soldiers, and 140 horses was guided by a Native American. Together they took a southern route along the Rio Altar, then paralleled the modern Mexico California border. The expedition crossed the Colorado River at its confluence with the Gila River. The expedition was observed by Viceroy and King and they decided that De Anza should lead a group of colonists to Alta California. The expedition arrived at Mission San Gabriel Arcángel in January, 1776 and continued to Monterey with the colonists. De Anza and 247 colonists arrived at the future site of San Francisco on this day in 1776. De Anza established a presidio, or military fort, on the tip of the San Francisco peninsula. Six months later, a Spanish Franciscan priest founded a mission near the presidio that he named in honor of St. Francis of Assisi – in Spanish, San Francisco de Asiacutes. However, San Francisco remained an isolated settlement for many years after Anza founded the first settlement. It is believed that in the 1830s, the potential of the area was eventually realized. Back then, San Francisco was only a rather small town of 900 people, but after gold had been discovered, more and more settlers came to the city and by the 1850s, it is believed that more than 36.000 people lived there. Juan Bautista de Anza himself was appointed governor of New Mexico in 1777. He negotiated a critical peace treaty with Commanche Indians, who agreed to join the Spanish in making war on the Apache. He retired in 1786 and passed away two years later. At yovisto you may learn more about Native Americans in a lecture at Berkeley University.]]></raw>\n",
    "</NAF>\"\"\"\n",
    "\n",
    "def procesar_texto(text: str) -> str:\n",
    "    \"\"\" Procesa el texto para eliminar espacios innecesarios, lematizar y tokenizar.\n",
    "    Args:\n",
    "        text (str): Texto a procesar.\n",
    "    Returns:\n",
    "        list: Lista de tokens lematizados, excluyendo stop words y puntuación.\n",
    "    \"\"\"\n",
    "    \n",
    "    # --- LIMPIEZA ---\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    text = re.sub(r'\\s+\\.', '.', text)  # quita espacios antes de puntos\n",
    "\n",
    "    # --- CARGA DE MODELO SPACY ---\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # --- TOKENS LEMATIZADOS ---\n",
    "    tokens = [\n",
    "        token.lemma_.lower()\n",
    "        for token in doc\n",
    "        if not token.is_stop\n",
    "        and not token.is_punct\n",
    "        and not token.is_space\n",
    "        and not token.like_num  # excluye números\n",
    "        and token.is_alpha      # excluye tokens con caracteres no alfabéticos\n",
    "    ]\n",
    "    return tokens\n",
    "\n",
    "def preprocesamiento_xml(xml_data: str) -> list:\n",
    "    \"\"\"\n",
    "    Procesa un documento XML en formato NAF para extraer y limpiar el texto,\n",
    "    y luego tokenizar y lematizar el contenido utilizando spaCy.\n",
    "\n",
    "    Args:\n",
    "        xml_data (str): Cadena que contiene el documento XML en formato NAF.\n",
    "\n",
    "    Returns:\n",
    "        list: Lista de tokens lematizados, excluyendo stop words y puntuación.\n",
    "    \"\"\"\n",
    "    ruta = \"docs-raw-texts/\"+xml_data\n",
    "    tokens = []\n",
    "    # Verifica si existe el archivo y lo lee\n",
    "    if os.path.exists(ruta):\n",
    "\n",
    "        with open(ruta, 'r', encoding='utf-8') as file:\n",
    "            xml_data = file.read()\n",
    "\n",
    "        # --- PARSEO Y EXTRACCIÓN DEL TEXTO CON LXML ---\n",
    "        parser = etree.XMLParser(strip_cdata=False)\n",
    "        root = etree.fromstring(xml_data.encode('utf-8'), parser=parser)\n",
    "\n",
    "        raw_texts = root.xpath('//raw/text()')\n",
    "        if raw_texts:\n",
    "            # Si hay varios <raw>, los unimos\n",
    "            text = \" \".join(raw_texts)\n",
    "\n",
    "            return procesar_texto(text)\n",
    "\n",
    "    return tokens\n",
    "\n",
    "# Ejemplo de uso\n",
    "tokens = preprocesamiento_xml(\"wes2015.d001.naf\")\n",
    "tokens[:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1daa403",
   "metadata": {},
   "source": [
    "### Extracción y tokenización (Docs-raw-texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3c5e397d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Termino</th>\n",
       "      <th>DocID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>william</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>beaumont</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>human</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>digestion</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>william</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Termino  DocID\n",
       "0    william      1\n",
       "1   beaumont      1\n",
       "2      human      1\n",
       "3  digestion      1\n",
       "4    william      1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = {}\n",
    "\n",
    "for i in range(1, 332):\n",
    "    file_name = f\"wes2015.d{i:03d}.naf\"\n",
    "    tokens = preprocesamiento_xml(file_name)\n",
    "    docs[i] = tokens\n",
    "\n",
    "rows = [(term, doc_id) for doc_id, terms in docs.items() for term in terms]\n",
    "\n",
    "df = pd.DataFrame(rows, columns=[\"Termino\", \"DocID\"])\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "04141131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Termino</th>\n",
       "      <th>tf</th>\n",
       "      <th>Postings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aachen</td>\n",
       "      <td>4</td>\n",
       "      <td>[139, 161, 252]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aazv</td>\n",
       "      <td>1</td>\n",
       "      <td>[156]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ab</td>\n",
       "      <td>1</td>\n",
       "      <td>[224]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abadone</td>\n",
       "      <td>1</td>\n",
       "      <td>[62]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abandon</td>\n",
       "      <td>20</td>\n",
       "      <td>[3, 11, 14, 18, 35, 52, 56, 76, 84, 92, 107, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14692</th>\n",
       "      <td>čech</td>\n",
       "      <td>1</td>\n",
       "      <td>[238]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14693</th>\n",
       "      <td>łukasiewicz</td>\n",
       "      <td>2</td>\n",
       "      <td>[227]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14694</th>\n",
       "      <td>šufflay</td>\n",
       "      <td>1</td>\n",
       "      <td>[293]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14695</th>\n",
       "      <td>λ</td>\n",
       "      <td>1</td>\n",
       "      <td>[220]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14696</th>\n",
       "      <td>π</td>\n",
       "      <td>1</td>\n",
       "      <td>[273]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14697 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Termino  tf                                           Postings\n",
       "0           aachen   4                                    [139, 161, 252]\n",
       "1             aazv   1                                              [156]\n",
       "2               ab   1                                              [224]\n",
       "3          abadone   1                                               [62]\n",
       "4          abandon  20  [3, 11, 14, 18, 35, 52, 56, 76, 84, 92, 107, 1...\n",
       "...            ...  ..                                                ...\n",
       "14692         čech   1                                              [238]\n",
       "14693  łukasiewicz   2                                              [227]\n",
       "14694      šufflay   1                                              [293]\n",
       "14695            λ   1                                              [220]\n",
       "14696            π   1                                              [273]\n",
       "\n",
       "[14697 rows x 3 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grouped = (\n",
    "    df.groupby(\"Termino\")\n",
    "      .agg(\n",
    "          tf=(\"Termino\", \"size\"),            # Conteo de apariciones\n",
    "          Postings=(\"DocID\", lambda x: sorted(set(x)))  # Lista única de DocID ordenada\n",
    "      )\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "df_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2837b521",
   "metadata": {},
   "source": [
    "### Consultas binarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87b96d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def consulta_binaria(terms_included: list, terms_not_included: list,  df: pd.DataFrame) -> list:\n",
    "    \"\"\"\n",
    "    Realiza una consulta binaria sobre un DataFrame de términos y sus documentos.\n",
    "\n",
    "    Args:\n",
    "        terms_included (list): Lista de términos a incluir en la consulta.\n",
    "        terms_not_included (list): Lista de términos a excluir de la consulta.\n",
    "        df (pd.DataFrame): DataFrame con columnas 'Termino' y 'DocID'.\n",
    "\n",
    "    Returns:\n",
    "        list: Mezcla de listas dejando los docsID que contienen los términos incluidos y excluyendo los que contienen los términos no incluidos.\n",
    "    \"\"\"\n",
    "    if not query:\n",
    "        return []\n",
    "\n",
    "    # Filtra el DataFrame por los términos de la consulta\n",
    "    filtered_df = df[df['Termino'].isin(query)]\n",
    "\n",
    "    # Agrupa por DocID y verifica si hay al menos un término presente\n",
    "    grouped = filtered_df.groupby('DocID').size().reset_index(name='count')\n",
    "\n",
    "    # Crea una lista binaria según la presencia de términos en los documentos\n",
    "    return [1 if doc in grouped['DocID'].values else 0 for doc in range(1, 333)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
